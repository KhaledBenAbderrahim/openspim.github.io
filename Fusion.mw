= Fusion = 

[[Registration|'''Registered''']] multi-view OpenSPIM data need to be fused into a single output image in order to achieve complete coverage of a large specimen. Fusion means here combining information from different views in areas where the views overlap. Several strategies to do so exist, many are published (ADD REFS LATER). We will focus here on the two fusion methods implemented in Fiji - the content based multiview fusion and multiview deconvolution.


''Note that fused data are different, not necessarily better compared to raw SPIM data. Both fusion algorithms described here potentially deteriorate the quality of the data in some respects while improving other aspects. We will discuss the fusion artefacts in the respective sections. However it should be said that sometimes it is beneficial to NOT fuse the data at all and perform analysis on the raw registered image stacks (for example segmentation of cells in the individual views and reconciliation of the results in the segmentation domain). In the section on of this tutorial on [[Browsing|'''browsing''']] we will describe how to view raw registered multi-view OpenSPIM views.

= Content Based Fusion =

The content based multi-view fusion evaluates local information entropy in the areas where several views overlap and combines the views by enhancing  the low entropy information from the view containing useful data while suppressing the high entropy noise from the blurred data in other views. The principles of the method are discussed in depth [http://fiji.sc/SPIM_Registration_Method#Image_Fusion_and_blending '''here'''] and the parameters of the Fiji plugin implementing the method are described [http://fiji.sc/Multi-View_Fusion '''here''']. As before we enhance these technical description with tutorial style walk through using the [[Raw_data|sample OpenSPIM data]]. 

Content based multi-view fusion requires significant [[Pre-requisites|computational resources]]. The input raw data stacks are large and when they are transformed to the position where they overlap, the bounding box of the output volume can become several fold larger. To process on such large volumes can take significant amount of time and it may fail due to insufficient memory even on the largest computer systems (we did experience out of memory exceptions on a system with 128GB of RAM!). Therefore we will proceed sequentially, minimising the memory footprint.

* first we will fuse '''four times down-sampled''' data with all computationally demanding options turned off - see [[Fusion#First_approximate_run|'''First approximate run''']].
* next we will '''crop''' the output volume to include only the specimen - see [[Fusion#Cropping|'''Cropping''']].
* finally we will fuse the '''cropped''' volume with all options turned on - see [[Fusion#Final_run|'''Final run''']].

== First approximate run ==

The purpose of this run is to get to the output fused data as quickly as possible in order to evaluate them and decide on how to continue.

=== Input ===
{|
|-
|
[[File:Screenshot-fusion-pluginselection.png|thumb|200px|right|Launching content based multi-view fusion]]
We start the Content based fusion plugin from '''Plugins->SPIM Registration->Multi-view fusion''' (or pressing letter '''l''' and typing Multi etc.).
|-
|
----
[[File:Screenshot-Multi-view fusion-dialog1.png|thumb|400px|right|Screenshot of the first fusion dialog]]
In the first dialog we will accept the default '''Single channel''' channel type option and click '''Ok'''.
|-
|
----
[[File:Screenshot-Multi-view fusion-dialog2.png|thumb|400px|right|Screenshot of the second fusion dialog]]
The second dialog should look familiar. In fact if you have run the [[Registration|'''registration''']] of timepoint '''5''' before it should be pre-filled with all the necessary data (SPIM data directory, Pattern of SPIM file, Time-points to process and Angles to process). See [[Registration|registrarion]] tutorial for details on the fields. To proceed with fusion of time-point 5 click '''Ok'''.
|-
|
----
[[File:Screenshot-Multi-View Fusion-main-dialog.png|thumb|400px|right|Screenshot of the main fusion dialog]]
The main dialog of Content based fusion plugin starts with a pull-down '''Registration of channel 0'''. This pull down should have only a single option available '''Individual registration to channel 0'''. Later on, after we perform [[Timelapse_Registration|timelapse registration]] there will be other possibilities. For now it is sufficient to know that this field refers to the ''.registration'' files in the ''/registration'' directory that contains the [[Registration#Output|registration results]] (affine transformation matrices). The files need to exist in that directory otherwise the fusion will fail.


Second field '''Fusion Method''' can be left as default, we want to fuse the data into a single image.


On our 128GB computer we can '''Process All views in parallel''' we have enough memory. However if you are using a lesser computer and getting the so-called ''Java heap space'' exception after launching fusion, you need to choose to process '''2''' or maybe only '''one view''' in parallel. ''Note that this is unlilkely to be a problem if you follow this tutorial since we will downsample the image four times, making it rather small - see below''.


'''Blending''', '''Content based weights''' and '''Content based weights (fast approximate)''' are options that take time and so we leave the checkboxes '''unclicked''' for this initial quick run. We will return to them later when discussing the [[Fusion#Final_run|'''final run''']].


Importantly, to speed up the processing we enter '''4''' into the '''Downsample output image n-times'''.


We will leave the '''cropping''' fields at 0 (we return them in the chapter [[Fusion#Cropping|'''cropping''']]).


Finally, the last pull down menu '''Fused image output''' allows us to choose to either

* ''Display only'' - simply display the output without saving
* ''Save 2d-slices, all in one directory'' - save the output volume into a single directory one image per slice. ''Note that when processing long-term time-lapse this can amount to literally hundreds of thousands of images, it has benefits in terms of loading the data into Fiji as virtual stack, but your file system may not like it, thus...
* ''Save 2d-slices, one directory per timepoint'' - is a more sensible option, it will put all slices for one timepoint into a directory named by the timepoint index, i.e. for timepoint 5 it will be directory '''output/5'''


We are ready to launch the fusion by clicking '''OK'''.
|}

===  Run ===

[[File:Fusion-Log.png|thumb|400px|right|Fusion output in the log window]]
As before, let us annotate the output the fusion plugin sends to the '''Log''' window.
 
 dir: /home/tomancak/Desktop/OpenSPIM_for_website/tiffs/registration
 spim_TL05_Angle0.tif.registration
 Z-stretching = <font color=red>9.30232558139535</font>

The plugin identifies the registration files and reads in the z-scaling.

 0: -1
 channel 0 takes it from channel 0
 tp -1
 Version 0.55
 (Thu Jun 06 00:11:09 CEST 2013): Starting Bead Extraction
 Read 1046 beads for spim_TL05_Angle0.tif (id = 0)
 Read 1172 beads for spim_TL05_Angle1.tif (id = 1) 
 Read 1009 beads for spim_TL05_Angle2.tif (id = 2) 
 Read 1039 beads for spim_TL05_Angle3.tif (id = 3)
 Read 1212 beads for spim_TL05_Angle4.tif (id = 4)
 (Thu Jun 06 00:11:09 CEST 2013): Finished Bead Extraction
 (Thu Jun 06 00:11:09 CEST 2013): Starting Registration
 (Thu Jun 06 00:11:09 CEST 2013): Finished Registration

It then repeats the registration steps. We will recall that the actual registration took very short time, once the beads are segmented reading them in and repeating the optimization is simpler then programming a specific function that would load the matrices from the files (apparently - Stephan?). 

 (Thu Jun 06 00:11:09 CEST 2013): Starting Fusion
 Dimension of final output image:
 From : (0.0, 0.0, -485.1395) to (1535.1057, 1127.0483, 984.4027)
 Size: (1535.1057, 1127.0483, 1469.5422) needs <font color=red>9699 MB</font> of RAM
 Scaled size(4): (384, 282, 367) needs <font color=red>152 MB</font> of RAM

Here we see the benefits of downsampling, the full resolution output image would need almost 10GB of RAM and thats only the final output excluding all intermediate steps - the actual memory footprint is several fold higher. One can easily run out of memory with this data. However scaled we are down to much more reasonable 152MB for the output image.

 Location of pixel (0,0,0) in global coordinates is: (0.0, 0.0, -485.1395)
 (Thu Jun 06 00:11:09 CEST 2013): Reserving memory for fused image.
 Loading source images (Channel 0).
 (Thu Jun 06 00:11:17 CEST 2013): Computing output image (Channel 0).
 (Thu Jun 06 00:11:19 CEST 2013): Closing all input images (Channel 0).
 (Thu Jun 06 00:11:19 CEST 2013): Done computing output image (Channel 0).
 (Thu Jun 06 00:11:19 CEST 2013): Displaying image (Channel 0).
 (Thu Jun 06 00:11:20 CEST 2013): Finished Fusion
 Finished processing.

Now here is the action, the plugin loads the images, fuses them without doing any entropy evaluation, closes the input images and displays the output. Since we are working with 4 times down-sampled data it all takes only seconds.

A new window will pop-up. This is the '''Output''' that we will discuss in the next section.

=== Output and Evaluation ===
{|
|-
|colspan="3"|
[[File:Screenshot-Fused spim TL5.png|thumb|400px|right|4 times downsampled fusion output, auto contrast adjusted]]
At end of the '''Run''' a new window pops up. Now we finally see our registered OpenSPIM data albeit heavily downsampled.


This is not exactly what we hoped for, there are lines and grey boxes everywhere and the resolution is poor. This is because we downsampled and turned off all fusion bells and whistles. When we scroll through the stack we nonetheless can see that the 5 views making up this timepoint have indeed been registered as there are no obvious discontinuities in the data and the entire embryo is covered. 


We are looking at the data from the point of view of the reference view (in this case Angle0). This view hasn't been transformed, we are looking at the data as they were acquired, downsampled and degraded by averaging in the blurred data from other views (we did no content based weightening).
|-
|We will use this initial output to demonstrate the fundamental principle of the bead based multi-view registration. Lets turn this stack to look at it along the rotation axis. We do that by running '''Plugins->Transform->TransformJ->TransfromJ Turn''' and turning the fusion output stack around the '''x''' axis by '''90 degrees'''.
|[[File:Screenshot-TransformJ.png|thumb|200px|right|Run TransformJ Turn command]]
|[[File:Screenshot-TransformJ-Turn.png|thumb|150px|right|Turn by 90 degrees around the x axis]]



|-
|
When we now navigate through the turned stack we are looking approximately alongside the rotation axis. We see how the five individual view stacks overlap in the output volume and how the bounding box of that volume becomes consequently large.


We see also the elongated '''Point Spread Function''' ('''PSF'''s) of the beads. These axially elongated PSFs cross forming beautiful stars. Their presence around the specimen indicates that the registration was successful. 
|[[File:Screenshot-Fused spim TL5 turned.png|200px|right|Turned fusion output stack - looking roughly alongside the rotation axis]]
|[[File:Screenshot-Fused spim TL5 turned psf.png|200px|right|Turned fusion output stack - looking roughly alongside the rotation axis]]
|}

== Cropping ==

In the next step of the fusion pipeline we will crop the output image as much as possible. Why? You may have noticed that the bounding box of the fused image is actually rather large (4 x 384x282x367). This is because we have rotated the input image stacks in 3d and the resulting cubic volume has to include them all. Saving output images in this form would increase the storage requirements by orders of magnitude. To reduce the storage footprint we will use this initial run of fusion to define a volume that fits the specimen most efficiently. It will also reduce memory requirements allowing us to run the fusion with full resolution images.


''Note that in reality it makes sense to define the crop volume only after the [[Timelapse_Registration|time-lapse registration]], because that will be the final output of the pipeline and the crop area has to be defined relative to that registration. However to preserve linearity we will describe cropping here.


{|
|-
|
Before you start cropping start a macro recorder. '''Macro recorder''' will open a window that will report the parameters of commands we run in Fiji. We will need it to note the coordinates of the bounding box.
| colspan="2" |
[[File:Macro recorder.png|thumb|400px|Screenshot of macro recorder, showing where to find it in Fiji menus and the recorder window which has just recorded the running of the macro recorder command (little recursion)]]
|-
|
To define the crop area we click on the '''rectangle tool''' in the main Fiji window and make a rectangle around the contrast adjusted fused data. Move up and down through the z stack to make sure that the rectangle includes all the data. Modify the size of the rectangle by dragging the tiny boxes on the rectangle. Make the rectangle tight around the data but leave a few pixels buffer zone. Note that everytime you adjust the rectangle a new command get recorded in the '''Recorder''' window, such as '''makeRectangle(109, 53, 138, 172);'''. The numbers have the following meaning:

* 109 - x coordinate (offset from upper left corner along the x axis)
* 53 - y coordinate (offset from upper left corner along the y axis)
* 138 - width of the rectangle
* 172 - height of the rectangle

''Note that we will need those numbers - so either write them down or keep the Recorder window open, which is the point of running it in the first place.


Now we run the '''Crop''' function from the Fiji menus which will crop the image to the size of the placed rectangle.
|
[[File:Crop2.png|thumb|200px|Screenshot of using rectangular tool adjust xy cropping area, note the macro recorded coordinates]]
[[File:Crop3.png|thumb|200px|Running crop command from Fiji menu]]
|[[File:Crop4.png|thumb|200px|Output volume cropped in xy]]
|-
|
The cropped image is still too big in the z-direction. Once again move the z-slider up and down to determine at which z-index the data start and end. Remember the two z-indices (for this data roughly 120 and 240). Now to also record them we will run the command '''Duplicate''' stack from Fiji menus and fill in the numbers as shown on the screenshots to the right. Running the command will duplicate the stack and make it as small as possible without discarding any data. The range will also be recorded in the recorder as highlighted: 


* 120 - offset from the bottom of the stack to the bottom of the specimen (the part away from you)
* 240 - offset from the bottom of the stack to the top of the specimen (the part closer to you)


We are done with cropping, we can now proceed to run the fusion one more time with all the bells and whistles turned on taking advantage of the crop parameters to reduce the memory requirements.
|
[[File:Crop5.png|thumb|200px|Running the duplicate command from Fiji menus]]
[[File:Crop6.png|thumb|200px|Filling in the z-index of the bottom and end the top of the specimen]]
|
[[File:Crop7.png|thumb|200px|Duplicated fully cropped output stack and the recorded duplicate command range]]
|}

== Final run ==

Now that we figured out the minimal crop area we will fuse the data at full resolution.

{|
|-
|
Start once again the '''Plugins->SPIM registration->Multi-view fusion''' plugin and click through the first two windows, the parameters should be pre-filled (unless you restarted Fiji in the meantime). 


''We are still working only with the time-point number five''.
|
[[File:Screenshot-fusion-pluginselection.png|thumb|200px|right|Launching content based multi-view fusion]]
|
[[File:Screenshot-Multi-view fusion-dialog1.png|thumb|200px|right|Screenshot of the first fusion dialog]]
[[File:Screenshot-Multi-view fusion-dialog2.png|thumb|200px|right|Screenshot of the second fusion dialog]]
|-
|

|

|}

= Deconvolution =

== Scaling of input data ==

== Debug run ==

== Final run ==

== Using GPUs ==
